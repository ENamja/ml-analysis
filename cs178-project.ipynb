{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377c837e-2921-467b-ae5f-3a9152754e52",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h3> CS 178: Machine Learning & Data Mining </h3>\n",
    "<h2> An Investigation of Classification Methods for Diabetes 130-US Hospitals </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5d21f9-cc02-4d7b-a9c8-d2665882809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 296, 'name': 'Diabetes 130-US Hospitals for Years 1999-2008', 'repository_url': 'https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008', 'data_url': 'https://archive.ics.uci.edu/static/public/296/data.csv', 'abstract': 'The dataset represents ten years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. Each row concerns hospital records of patients diagnosed with diabetes, who underwent laboratory, medications, and stayed up to 14 days. The goal is to determine the early readmission of the patient within 30 days of discharge.\\nThe problem is important for the following reasons. Despite high-quality evidence showing improved clinical outcomes for diabetic patients who receive various preventive and therapeutic interventions, many patients do not receive them. This can be partially attributed to arbitrary diabetes management in hospital environments, which fail to attend to glycemic control. Failure to provide proper diabetes care not only increases the managing costs for the hospitals (as the patients are readmitted) but also impacts the morbidity and mortality of the patients, who may face complications associated with diabetes.\\n', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 101766, 'num_features': 47, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Race', 'Gender', 'Age'], 'target_col': ['readmitted'], 'index_col': ['encounter_id', 'patient_nbr'], 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2014, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5230J', 'creators': ['John Clore', 'Krzysztof Cios', 'Jon DeShazo', 'Beata Strack'], 'intro_paper': {'title': 'Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Record', 'authors': 'Beata Strack, Jonathan DeShazo, Chris Gennings, Juan Olmo, Sebastian Ventura, Krzysztof Cios, John Clore', 'published_in': 'BioMed Research International, vol. 2014', 'year': 2014, 'url': 'https://www.hindawi.com/journals/bmri/2014/781670/', 'doi': None}, 'additional_info': {'summary': 'The dataset represents ten years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.\\n(1)\\tIt is an inpatient encounter (a hospital admission).\\n(2)\\tIt is a diabetic encounter, that is, one during which any kind of diabetes was entered into the system as a diagnosis.\\n(3)\\tThe length of stay was at least 1 day and at most 14 days.\\n(4)\\tLaboratory tests were performed during the encounter.\\n(5)\\tMedications were administered during the encounter.\\n\\nThe data contains such attributes as patient number, race, gender, age, admission type, time in hospital, medical specialty of admitting physician, number of lab tests performed, HbA1c test result, diagnosis, number of medications, diabetic medications, number of outpatient, inpatient, and emergency visits in the year before the hospitalization, etc.', 'purpose': None, 'funded_by': None, 'instances_represent': 'The instances represent hospitalized patient records diagnosed with diabetes.', 'recommended_data_splits': 'No recommendation. The standard train-test split could be used. Can use three-way holdout split (i.e., train-validation-test) when doing model selection.', 'sensitive_data': 'Yes. The dataset contains information about the age, gender, and race of the patients.', 'preprocessing_description': None, 'variable_info': 'Detailed description of all the atrributes is provided in Table 1 Beata Strack, Jonathan P. DeShazo, Chris Gennings,  Juan L. Olmo, Sebastian Ventura,  Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.\\n\\nhttp://www.hindawi.com/journals/bmri/2014/781670/', 'citation': 'Please cite:\\nBeata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, “Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,” BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.'}}\n",
      "                        name     role         type demographic  \\\n",
      "0               encounter_id       ID                     None   \n",
      "1                patient_nbr       ID                     None   \n",
      "2                       race  Feature  Categorical        Race   \n",
      "3                     gender  Feature  Categorical      Gender   \n",
      "4                        age  Feature  Categorical         Age   \n",
      "5                     weight  Feature  Categorical        None   \n",
      "6          admission_type_id  Feature  Categorical        None   \n",
      "7   discharge_disposition_id  Feature  Categorical        None   \n",
      "8        admission_source_id  Feature  Categorical        None   \n",
      "9           time_in_hospital  Feature      Integer        None   \n",
      "10                payer_code  Feature  Categorical        None   \n",
      "11         medical_specialty  Feature  Categorical        None   \n",
      "12        num_lab_procedures  Feature      Integer        None   \n",
      "13            num_procedures  Feature      Integer        None   \n",
      "14           num_medications  Feature      Integer        None   \n",
      "15         number_outpatient  Feature      Integer        None   \n",
      "16          number_emergency  Feature      Integer        None   \n",
      "17          number_inpatient  Feature      Integer        None   \n",
      "18                    diag_1  Feature  Categorical        None   \n",
      "19                    diag_2  Feature  Categorical        None   \n",
      "20                    diag_3  Feature  Categorical        None   \n",
      "21          number_diagnoses  Feature      Integer        None   \n",
      "22             max_glu_serum  Feature  Categorical        None   \n",
      "23                 A1Cresult  Feature  Categorical        None   \n",
      "24                 metformin  Feature  Categorical        None   \n",
      "25               repaglinide  Feature  Categorical        None   \n",
      "26               nateglinide  Feature  Categorical        None   \n",
      "27            chlorpropamide  Feature  Categorical        None   \n",
      "28               glimepiride  Feature  Categorical        None   \n",
      "29             acetohexamide  Feature  Categorical        None   \n",
      "30                 glipizide  Feature  Categorical        None   \n",
      "31                 glyburide  Feature  Categorical        None   \n",
      "32               tolbutamide  Feature  Categorical        None   \n",
      "33              pioglitazone  Feature  Categorical        None   \n",
      "34             rosiglitazone  Feature  Categorical        None   \n",
      "35                  acarbose  Feature  Categorical        None   \n",
      "36                  miglitol  Feature  Categorical        None   \n",
      "37              troglitazone  Feature  Categorical        None   \n",
      "38                tolazamide  Feature  Categorical        None   \n",
      "39                   examide  Feature  Categorical        None   \n",
      "40               citoglipton  Feature  Categorical        None   \n",
      "41                   insulin  Feature  Categorical        None   \n",
      "42       glyburide-metformin  Feature  Categorical        None   \n",
      "43       glipizide-metformin  Feature  Categorical        None   \n",
      "44  glimepiride-pioglitazone  Feature  Categorical        None   \n",
      "45   metformin-rosiglitazone  Feature  Categorical        None   \n",
      "46    metformin-pioglitazone  Feature  Categorical        None   \n",
      "47                    change  Feature  Categorical        None   \n",
      "48               diabetesMed  Feature  Categorical        None   \n",
      "49                readmitted   Target  Categorical        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                   Unique identifier of an encounter  None             no  \n",
      "1                      Unique identifier of a patient  None             no  \n",
      "2   Values: Caucasian, Asian, African American, Hi...  None            yes  \n",
      "3           Values: male, female, and unknown/invalid  None             no  \n",
      "4   Grouped in 10-year intervals: [0, 10), [10, 20...  None             no  \n",
      "5                                   Weight in pounds.  None            yes  \n",
      "6   Integer identifier corresponding to 9 distinct...  None             no  \n",
      "7   Integer identifier corresponding to 29 distinc...  None             no  \n",
      "8   Integer identifier corresponding to 21 distinc...  None             no  \n",
      "9   Integer number of days between admission and d...  None             no  \n",
      "10  Integer identifier corresponding to 23 distinc...  None            yes  \n",
      "11  Integer identifier of a specialty of the admit...  None            yes  \n",
      "12  Number of lab tests performed during the encou...  None             no  \n",
      "13  Number of procedures (other than lab tests) pe...  None             no  \n",
      "14  Number of distinct generic names administered ...  None             no  \n",
      "15  Number of outpatient visits of the patient in ...  None             no  \n",
      "16  Number of emergency visits of the patient in t...  None             no  \n",
      "17  Number of inpatient visits of the patient in t...  None             no  \n",
      "18  The primary diagnosis (coded as first three di...  None            yes  \n",
      "19  Secondary diagnosis (coded as first three digi...  None            yes  \n",
      "20  Additional secondary diagnosis (coded as first...  None            yes  \n",
      "21          Number of diagnoses entered to the system  None             no  \n",
      "22  Indicates the range of the result or if the te...  None             no  \n",
      "23  Indicates the range of the result or if the te...  None             no  \n",
      "24  The feature indicates whether the drug was pre...  None             no  \n",
      "25  The feature indicates whether the drug was pre...  None             no  \n",
      "26  The feature indicates whether the drug was pre...  None             no  \n",
      "27  The feature indicates whether the drug was pre...  None             no  \n",
      "28  The feature indicates whether the drug was pre...  None             no  \n",
      "29  The feature indicates whether the drug was pre...  None             no  \n",
      "30  The feature indicates whether the drug was pre...  None             no  \n",
      "31  The feature indicates whether the drug was pre...  None             no  \n",
      "32  The feature indicates whether the drug was pre...  None             no  \n",
      "33  The feature indicates whether the drug was pre...  None             no  \n",
      "34  The feature indicates whether the drug was pre...  None             no  \n",
      "35  The feature indicates whether the drug was pre...  None             no  \n",
      "36  The feature indicates whether the drug was pre...  None             no  \n",
      "37  The feature indicates whether the drug was pre...  None             no  \n",
      "38  The feature indicates whether the drug was pre...  None             no  \n",
      "39  The feature indicates whether the drug was pre...  None             no  \n",
      "40  The feature indicates whether the drug was pre...  None             no  \n",
      "41  The feature indicates whether the drug was pre...  None             no  \n",
      "42  The feature indicates whether the drug was pre...  None             no  \n",
      "43  The feature indicates whether the drug was pre...  None             no  \n",
      "44  The feature indicates whether the drug was pre...  None             no  \n",
      "45  The feature indicates whether the drug was pre...  None             no  \n",
      "46  The feature indicates whether the drug was pre...  None             no  \n",
      "47  Indicates if there was a change in diabetic me...  None             no  \n",
      "48  Indicates if there was any diabetic medication...  None             no  \n",
      "49  Days to inpatient readmission. Values: <30 if ...  None             no  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namel\\anaconda3\\envs\\cs178\\lib\\site-packages\\ucimlrepo\\fetch.py:97: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_url)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "seed=1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Import diabetes dataset\n",
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "\n",
    "# fetch dataset \n",
    "diabetes_df = fetch_ucirepo(id=296) \n",
    "\n",
    "# move data to features and target\n",
    "diabetes_X = diabetes_df.data.features \n",
    "diabetes_y = diabetes_df.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(diabetes_df.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(diabetes_df.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c309743-3abd-446e-86cd-58ca5a7affe8",
   "metadata": {},
   "source": [
    "We will do an analysis of different models in relation to the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64bc05b-b2db-4688-ab11-c4d9fe7f5f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race                         2273\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                      98569\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                  40256\n",
      "medical_specialty           49949\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                         21\n",
      "diag_2                        358\n",
      "diag_3                       1423\n",
      "number_diagnoses                0\n",
      "max_glu_serum                   0\n",
      "A1Cresult                       0\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in each column\n",
    "print(diabetes_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd7ba7-9946-45e2-8933-b9b8ebad7820",
   "metadata": {},
   "source": [
    "We see that the columns for weight, payer_code, and medical_specialty have a significant number of null values while the rest of the features are fairly reliable. We will drop these columns, and drop all rows and columns that have null values afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b35bf3a-6f5f-418a-99a4-ed66923ddbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = np.asarray(diabetes_X.columns)\n",
    "# hard to represent diag_1, diag_2, and diag_3 as numeric values\n",
    "# drop diag_1, diag_2, diag_3:\n",
    "rid_columns = ['weight', 'payer_code', 'medical_specialty']\n",
    "# rid_columns = ['weight', 'payer_code', 'medical_specialty']\n",
    "diabetes_X_drop = diabetes_X.loc[:, [col for col in all_columns if col not in rid_columns]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6de38-a0f6-43f0-82e9-9b053816632b",
   "metadata": {},
   "source": [
    "We can convert any non-numeric columns to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dc35ce-db76-43c6-900f-8be6067b95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "diags = ['diag_1', 'diag_2', 'diag_3']\n",
    "for diag in diags:\n",
    "    diabetes_X_drop[diag] = encoder.fit_transform(diabetes_X_drop[diag])\n",
    "\n",
    "diabetes_X_drop['gender'] = encoder.fit_transform(diabetes_X_drop['gender'])\n",
    "\n",
    "drugs = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
    "       'glyburide-metformin', 'glipizide-metformin',\n",
    "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "       'metformin-pioglitazone']\n",
    "\n",
    "for drug in drugs:\n",
    "    # # Encode values for drug use: \n",
    "    # diabetes_X_drop[drug] = encoder.fit_transform(diabetes_X_drop[drug])\n",
    "\n",
    "    # OR make drug use binary value (no = 0, everything else = 1)\n",
    "    diabetes_X_drop[drug] = [0 if y == 'NO' else 1 for y in diabetes_X_drop[drug]]\n",
    "\n",
    "# Convert age values\n",
    "age_mapping = {'[0-10)': 0, '[10-20)': 10, '[20-30)': 20, '[30-40)': 30, '[40-50)': 40, '[50-60)': 50, '[60-70)': 60, '[70-80)': 70, '[80-90)': 80, '[90-100)': 90}\n",
    "diabetes_X_drop['age'] = diabetes_X_drop['age'].map(age_mapping)\n",
    "\n",
    "# Convert change values\n",
    "diabetes_X_drop['change'] = diabetes_X_drop['change'].map({'No': 0, 'Ch': 1})\n",
    "\n",
    "# Convert diabetesMed values\n",
    "diabetes_X_drop['diabetesMed'] = diabetes_X_drop['diabetesMed'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Create multiple columns for races indicating binary values for yes or no\n",
    "diabetes_X_drop = pd.get_dummies(diabetes_X_drop, columns=['race'], prefix='race')\n",
    "\n",
    "# Create multiple columns for A1Cresult\n",
    "diabetes_X_drop = pd.get_dummies(diabetes_X_drop, columns=['A1Cresult'], prefix='A1Cresult')\n",
    "\n",
    "# Create multiple columns for max_glu_serum\n",
    "diabetes_X_drop = pd.get_dummies(diabetes_X_drop, columns=['max_glu_serum'], prefix='max_glu_serum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73846d3-3c79-4309-a689-5067ebf494ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What to do with NaN values - dropna(), replace(), or interpolate():\n",
    "\n",
    "# Drop columns where the percentage of missing values is greater than the threshold\n",
    "diabetes_clean_X = diabetes_X_drop.dropna()\n",
    "diabetes_clean_y = diabetes_y.iloc[diabetes_clean_X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0284d8ad-a339-473b-8907-df1536b4a150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 54)\n",
      "(101766, 1)\n",
      "(101766, 54)\n",
      "(101766, 1)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes_clean_X.shape)\n",
    "print(diabetes_clean_y.shape)\n",
    "\n",
    "# # Only use first 30,000 data points for testing:\n",
    "# diabetes_sub_X = diabetes_clean_X.iloc[:30000]\n",
    "# diabetes_sub_y = diabetes_clean_y.iloc[:30000]\n",
    "\n",
    "# Use all data points for testing:\n",
    "diabetes_sub_X = diabetes_clean_X\n",
    "diabetes_sub_y = diabetes_clean_y\n",
    "\n",
    "# Split data to 75% training data and 25% testing data\n",
    "diabetes_X_tr, diabetes_X_te, diabetes_y_tr, diabetes_y_te = train_test_split(diabetes_sub_X, diabetes_sub_y, test_size=0.25, random_state=seed, shuffle=True)\n",
    "\n",
    "print(diabetes_sub_X.shape)\n",
    "print(diabetes_sub_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498ec65-6d11-4d5c-ae46-a0c01b6de535",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1cf0b7-1d74-477d-924d-60cfa79193cb",
   "metadata": {},
   "source": [
    "Before Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0faf02e-a8ab-4f16-be4a-d67c1432cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, figsize=(6, 6))\n",
    "k_values = [1, 5, 10, 20, 50, 100]\n",
    "\n",
    "tr_error_rates = []\n",
    "te_error_rates = []\n",
    "\n",
    "diabetes_X_tr_arr = diabetes_X_tr.values\n",
    "diabetes_y_tr_arr = diabetes_y_tr.values.ravel()\n",
    "diabetes_X_te_arr = diabetes_X_te.values\n",
    "diabetes_y_te_arr = diabetes_y_te.values.ravel()\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(diabetes_X_tr_arr, diabetes_y_tr_arr)\n",
    "    tr_error_rates.append(1 - accuracy_score(diabetes_y_tr_arr, knn.predict(diabetes_X_tr_arr)))\n",
    "    te_error_rates.append(1 - accuracy_score(diabetes_y_te_arr, knn.predict(diabetes_X_te_arr)))\n",
    "axes.semilogx(k_values, tr_error_rates, label='Train')\n",
    "axes.semilogx(k_values, te_error_rates, label='Test')\n",
    "axes.set_xlabel('k')\n",
    "axes.set_ylabel('Error Rate')\n",
    "axes.set_title('Error Rates VS k')\n",
    "axes.legend(fontsize=12)\n",
    "axes.set_xticks(k_values)\n",
    "axes.set_xticklabels(k_values)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c17297-6f64-4301-a024-735952ec510d",
   "metadata": {},
   "source": [
    "After Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60087b5-df3d-4724-a76f-6b6e5ab3e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, figsize=(6, 6))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "tr_error_rates = []\n",
    "te_error_rates = []\n",
    "\n",
    "diabetes_X_tr_arr = scaler.fit_transform(diabetes_X_tr.values)\n",
    "diabetes_y_tr_arr = diabetes_y_tr.values.ravel()\n",
    "diabetes_X_te_arr = scaler.fit_transform(diabetes_X_te.values)\n",
    "diabetes_y_te_arr = diabetes_y_te.values.ravel()\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(diabetes_X_tr_arr, diabetes_y_tr_arr)\n",
    "    tr_error_rates.append(1 - accuracy_score(diabetes_y_tr_arr, knn.predict(diabetes_X_tr_arr)))\n",
    "    te_error_rates.append(1 - accuracy_score(diabetes_y_te_arr, knn.predict(diabetes_X_te_arr)))\n",
    "axes.semilogx(k_values, tr_error_rates, label='Train')\n",
    "axes.semilogx(k_values, te_error_rates, label='Test')\n",
    "axes.set_xlabel('k')\n",
    "axes.set_ylabel('Error Rate')\n",
    "axes.set_title('Error Rates VS k')\n",
    "axes.legend(fontsize=12)\n",
    "axes.set_xticks(k_values)\n",
    "axes.set_xticklabels(k_values)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a8bcb-e124-4f9f-aeba-1ee37ad0794e",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64b562-bcfb-4cea-9970-60b8ca122dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f93e8-5234-4882-aaa3-54d518d4acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Cost function\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    cost = -1/m * (np.dot(y, np.log(h)) + np.dot((1-y), np.log(1-h)))\n",
    "    return cost\n",
    "\n",
    "# Gradient descent function\n",
    "def gradient_descent(X, y, theta, learning_rate, num_iterations):\n",
    "    m = len(y)\n",
    "    cost_history = np.zeros(num_iterations)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        h = sigmoid(np.dot(X, theta))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        theta -= learning_rate * gradient\n",
    "        cost_history[i] = compute_cost(X, y, theta)\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "# One-vs-Rest (OvR) training for multiclass\n",
    "def one_vs_rest(X, y, num_classes, learning_rate, num_iterations):\n",
    "    m, n = X.shape\n",
    "    all_theta = np.zeros((num_classes, n))\n",
    "    for i in range(num_classes):\n",
    "        # Create binary labels for class i vs. all other classes\n",
    "        y_binary = (y == i).astype(int)\n",
    "        theta = np.zeros(n)\n",
    "        theta, _ = gradient_descent(X, y_binary, theta, learning_rate, num_iterations)\n",
    "        all_theta[i, :] = theta\n",
    "    return all_theta\n",
    "\n",
    "# Predict classes for multiclass\n",
    "def predict_multiclass(X, all_theta):\n",
    "    # Compute the probability for each class\n",
    "    h = sigmoid(np.dot(X, all_theta.T))\n",
    "    # Select the class with the highest probability\n",
    "    return np.argmax(h, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b206330-f8f9-403b-98c2-c754be9c4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No penalty\n",
    "y_1 = LabelEncoder().fit_transform(diabetes_y_tr_arr)\n",
    "y_test_1 = LabelEncoder().fit_transform(diabetes_y_te_arr)\n",
    "X_1 = scaler.fit_transform(diabetes_X_tr_arr)\n",
    "X_1 = np.hstack((np.ones((X_1.shape[0], 1)), X_1))\n",
    "X_test_1 = scaler.fit_transform(diabetes_X_te_arr)\n",
    "X_test_1 = np.hstack((np.ones((X_test_1.shape[0], 1)), X_test_1))\n",
    "\n",
    "num_classes = 3\n",
    "learning_rates = [0.01, 0.02, 0.05, 0.1, 0.5]\n",
    "num_iterations = 500\n",
    "\n",
    "for rate in learning_rates:\n",
    "    # Run gradient descent for every class\n",
    "    all_theta_train = one_vs_rest(X_1, y_1, num_classes, rate, num_iterations)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = predict_multiclass(X_1, all_theta_train)\n",
    "    y_pred_test = predict_multiclass(X_test_1, all_theta_train)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_accuracy = calculate_accuracy(y_1, y_pred_train)\n",
    "    print(f\"Train accuracy w/ learning rate {rate}:\", train_accuracy)\n",
    "    test_accuracy = calculate_accuracy(y_test_1, y_pred_test)\n",
    "    print(f\"Test accuracy w/ learning rate {rate}:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a786d1-0e1b-415a-996f-2c1ed287eb73",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92452bc2-c5a9-4233-afa4-91547f94ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running with different solvers\n",
    "# liblinear is only for binary classification\n",
    "liblinear_classifier = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=True)\n",
    "liblinear_classifier.fit(X_1, y_1)\n",
    "\n",
    "train_predictions = liblinear_classifier.predict(X_1)\n",
    "train_accuracy = np.mean(train_predictions == y_1)\n",
    "\n",
    "print('\\nTraining accuracy liblinear:',format( 100*train_accuracy , '.2f') ) \n",
    "\n",
    "# testing rest of classifiers but giving only 60% acc\n",
    "lbfgs_classifier = LogisticRegression(penalty='l2', solver='lbfgs', fit_intercept=True)\n",
    "lbfgs_classifier.fit(X_1, y_1)\n",
    "\n",
    "train_predictions = lbfgs_classifier.predict(X_1)\n",
    "train_accuracy = np.mean(train_predictions == y_1)\n",
    "\n",
    "print('\\nTraining accuracy lbfgs:',format( 100*train_accuracy , '.2f') ) \n",
    "\n",
    "penalties = ['l2', None]\n",
    "solvers = ['lbfgs', 'saga', 'sag', 'newton-cg']\n",
    "\n",
    "\n",
    "for solver in solvers:\n",
    "    for penalty in penalties:\n",
    "        classifier = LogisticRegression(penalty=penalty, solver=solver, fit_intercept=True, max_iter=1000)\n",
    "        classifier.fit(X_1, y_1)\n",
    "    \n",
    "        train_predictions = classifier.predict(X_1)\n",
    "        train_accuracy = np.mean(train_predictions == y_1)\n",
    "    \n",
    "        print('\\nTraining accuracy with penalty {} and solver {}: {:.2f}%'.format(penalty, solver, 100 * train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e5291-ec1d-4ef3-a377-6d8dd0fc01f9",
   "metadata": {},
   "source": [
    "### Forward Pass Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5aeadf-dec9-4878-bec7-978f8842e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005d2a8-210e-4f55-b4a5-70a55b7038c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_tr: np.array, X_te: np.array) -> tuple[np.array, np.array]:\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_tr)\n",
    "    \n",
    "    X_tr_scaled = scaler.transform(X_tr)\n",
    "    X_te_scaled = scaler.transform(X_te)\n",
    "    ###  YOUR CODE ENDS HERE  ###\n",
    "    return X_tr_scaled, X_te_scaled\n",
    "\n",
    "X_tr_scaled, X_te_scaled = scale_data(diabetes_X_tr.values, diabetes_X_te.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731be5c7-fc1d-40de-8e07-2d40c2425552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_for_train_sizes_mlp(X_tr: np.array, y_tr: np.array, X_te: np.array, y_te: np.array, seed: int, train_sizes: list[int]) -> tuple[list, list, list, list]:\n",
    "    # append error rates to the following lists\n",
    "    tr_err_mlp = [] # training error rates for MLP\n",
    "    te_err_mlp = [] # testing error rates for MLP\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    for size in train_sizes:\n",
    "        x_tr_sub = X_tr[:size]\n",
    "        y_tr_sub = y_tr[:size]\n",
    "        clf = MLPClassifier(hidden_layer_sizes=[64, 64], activation='relu', solver='sgd', learning_rate_init=0.001, batch_size=256, max_iter=1000, random_state=seed).fit(x_tr_sub, y_tr_sub)\n",
    "        tr_err_mlp.append(1 - clf.score(x_tr_sub, y_tr_sub))\n",
    "        te_err_mlp.append(1 - clf.score(X_te, y_te))\n",
    "    \n",
    "    ###  YOUR CODE ENDS HERE  ###\n",
    "    return tr_err_mlp, te_err_mlp # DO NOT CHANGE THIS LINE\n",
    "\n",
    "def errors_for_train_sizes_lr(X_tr: np.array, y_tr: np.array, X_te: np.array, y_te: np.array, seed: int, train_sizes: list[int]) -> tuple[list, list, list, list]:    \n",
    "    # append error rates to the following lists\n",
    "    tr_err_lr = [] # training error rates for Logistic Regression\n",
    "    te_err_lr = [] # testing error rates for Logistic Regression\n",
    "    \n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    for size in train_sizes:\n",
    "        x_tr_sub = X_tr[:size]\n",
    "        y_tr_sub = y_tr[:size]\n",
    "        clf = LogisticRegression(random_state=seed).fit(x_tr_sub, y_tr_sub)\n",
    "        tr_err_lr.append(1 - clf.score(x_tr_sub, y_tr_sub))\n",
    "        te_err_lr.append(1 - clf.score(X_te, y_te))\n",
    "        \n",
    "    ###  YOUR CODE ENDS HERE  ###\n",
    "    return tr_err_lr, te_err_lr # DO NOT CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b0543-52fb-436b-8046-fc55489325e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors_for_train_sizes_mlp_lr(tr_err_mlp: list, te_err_mlp: list, tr_err_lr: list, te_err_lr: list, train_sizes: list[int]) -> None:\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    # Please use semilogx to plot\n",
    "    plt.semilogx(train_sizes, tr_err_mlp, label=\"MLP Training\")\n",
    "    plt.semilogx(train_sizes, te_err_mlp, label=\"MLP Testing\")\n",
    "    plt.semilogx(train_sizes, tr_err_lr, label=\"LR Training\")\n",
    "    plt.semilogx(train_sizes, te_err_lr, label=\"LR Testing\")\n",
    "\n",
    "    plt.xlabel('Num. Training Data Points')\n",
    "    plt.ylabel('Error Rate')\n",
    "\n",
    "    plt.legend();\n",
    "    ###  YOUR CODE ENDS HERE  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeceb683-459a-4161-81cd-8ccc5caaa179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [50, 500, 2000, 5000, 10000, 15000, 25000]\n",
    "tr_err_mlp, te_err_mlp = errors_for_train_sizes_mlp(X_tr_scaled, diabetes_y_tr_arr, X_te_scaled, diabetes_y_te_arr, seed, train_sizes)\n",
    "tr_err_lr, te_err_lr = errors_for_train_sizes_lr(X_tr_scaled, diabetes_y_tr_arr, X_te_scaled, diabetes_y_te_arr, seed, train_sizes)\n",
    "plot_errors_for_train_sizes_mlp_lr(tr_err_mlp, te_err_mlp, tr_err_lr, te_err_lr, train_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457805c4-b288-4e3e-92fe-0cf1f3e0a2c2",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a97c16-17e5-4256-92d6-42eb0ed9c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83e6a2-d5ae-40bf-b442-adae6e0dd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 16)\n",
    "tr_scores = []\n",
    "te_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=seed)\n",
    "    clf.fit(X_tr_scaled, diabetes_y_tr_arr)\n",
    "    \n",
    "    tr_scores.append(clf.score(X_tr_scaled, diabetes_y_tr_arr))\n",
    "    te_scores.append(clf.score(X_te_scaled, diabetes_y_te_arr))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depths, tr_scores, label=\"Training Accuracy\")\n",
    "plt.plot(depths, te_scores, label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(depths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37953f64-7aaa-48c3-aa17-1a24cdfda642",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = range(1, 16)\n",
    "tr_scores = []\n",
    "te_scores = []\n",
    "\n",
    "for leaf in leaves:\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=leaf, random_state=seed)\n",
    "    clf.fit(X_tr_scaled, diabetes_y_tr_arr)\n",
    "    \n",
    "    tr_scores.append(clf.score(X_tr_scaled, diabetes_y_tr_arr))\n",
    "    te_scores.append(clf.score(X_te_scaled, diabetes_y_te_arr))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(leaves, tr_scores, label=\"Training Accuracy\")\n",
    "plt.plot(leaves, te_scores, label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"Min Leaf Samples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(leaves)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733fade-17ae-4b8b-b7cc-d0707ecc566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = range(9, 17)\n",
    "depths = range(2, 9)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for leaf in leaves:\n",
    "    for depth in depths:\n",
    "        clf = DecisionTreeClassifier(min_samples_leaf=leaf, max_depth=depth, random_state=seed)\n",
    "        clf.fit(X_tr_scaled, diabetes_y_tr_arr)\n",
    "\n",
    "        tr_score = clf.score(X_tr_scaled, diabetes_y_tr_arr)\n",
    "        te_score = clf.score(X_te_scaled, diabetes_y_te_arr)\n",
    "        leaf_depth = [leaf, depth]\n",
    "        scores.append([te_score, tr_score, leaf_depth])\n",
    "\n",
    "scores = sorted(scores, reverse=True)[:5]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dfdd9-61e3-4e95-b6dc-99f946c24aea",
   "metadata": {},
   "source": [
    "### Binary Class (Readmitted or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33da171-71f9-4169-966b-879c5a83a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change training and testing class labels to binary classifications\n",
    "diabetes_y_tr_arr = [0 if y == 'NO' else 1 for y in diabetes_y_tr_arr]\n",
    "diabetes_y_te_arr = [0 if y == 'NO' else 1 for y in diabetes_y_te_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55b671-9ce8-4b6b-bdf3-b0794bdcbcbc",
   "metadata": {},
   "source": [
    "### kNN (Binary Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72f485-efd8-43e7-8c69-a2d7ba0f86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, figsize=(6, 6))\n",
    "k_values = [1, 5, 10, 20, 50, 100]\n",
    "\n",
    "tr_error_rates = []\n",
    "te_error_rates = []\n",
    "\n",
    "diabetes_X_tr_arr = diabetes_X_tr.values\n",
    "diabetes_X_te_arr = diabetes_X_te.values\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(diabetes_X_tr_arr, diabetes_y_tr_arr)\n",
    "    tr_error_rates.append(1 - accuracy_score(diabetes_y_tr_arr, knn.predict(diabetes_X_tr_arr)))\n",
    "    te_error_rates.append(1 - accuracy_score(diabetes_y_te_arr, knn.predict(diabetes_X_te_arr)))\n",
    "axes.semilogx(k_values, tr_error_rates, label='Train')\n",
    "axes.semilogx(k_values, te_error_rates, label='Test')\n",
    "axes.set_xlabel('k')\n",
    "axes.set_ylabel('Error Rate')\n",
    "axes.set_title('Error Rates VS k')\n",
    "axes.legend(fontsize=12)\n",
    "axes.set_xticks(k_values)\n",
    "axes.set_xticklabels(k_values)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773897d-d976-453e-8660-5fca8d41273b",
   "metadata": {},
   "source": [
    "Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b75763-597f-4a7e-8493-76f576c058fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(1, figsize=(6, 6))\n",
    "k_values = [1, 5, 10, 20, 50, 100]\n",
    "\n",
    "tr_error_rates = []\n",
    "te_error_rates = []\n",
    "\n",
    "diabetes_X_tr_arr_sc = scaler.fit_transform(diabetes_X_tr.values)\n",
    "diabetes_X_te_arr_sc = scaler.fit_transform(diabetes_X_te.values)\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(diabetes_X_tr_arr_sc, diabetes_y_tr_arr)\n",
    "    tr_error_rates.append(1 - accuracy_score(diabetes_y_tr_arr, knn.predict(diabetes_X_tr_arr_sc)))\n",
    "    te_error_rates.append(1 - accuracy_score(diabetes_y_te_arr, knn.predict(diabetes_X_te_arr_sc)))\n",
    "axes.semilogx(k_values, tr_error_rates, label='Train')\n",
    "axes.semilogx(k_values, te_error_rates, label='Test')\n",
    "axes.set_xlabel('k')\n",
    "axes.set_ylabel('Error Rate')\n",
    "axes.set_title('Error Rates VS k')\n",
    "axes.legend(fontsize=12)\n",
    "axes.set_xticks(k_values)\n",
    "axes.set_xticklabels(k_values)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23131ce6-ff5b-4451-ae2a-a33dfb7da568",
   "metadata": {},
   "source": [
    "### Gradient Descent (Binary Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b42e66-c2d4-4809-b24f-e738058a8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def compute_loss(y, y_pred):\n",
    "    y = np.array(y)\n",
    "    m = len(y)\n",
    "    loss = - (1/m) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "# Define the gradient descent function\n",
    "def gradient_descent(X, y, learning_rate=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        linear_model = np.dot(X, weights) + bias\n",
    "        y_pred = sigmoid(linear_model)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = compute_loss(y, y_pred)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Compute gradients\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Update weights and bias\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    \n",
    "    return weights, bias, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711278c1-38b1-4e8e-b1bf-f20d4039d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.02, 0.05, 0.1, 0.5]\n",
    "num_iterations = 500\n",
    "\n",
    "for rate in learning_rates:\n",
    "    weights, bias, losses = gradient_descent(X_1, diabetes_y_tr_arr, rate, num_iterations)\n",
    "    \n",
    "    linear_model_tr = np.dot(X_1, weights) + bias\n",
    "    y_pred_tr = sigmoid(linear_model_tr)\n",
    "    tr_predictions = np.round(y_pred_tr)\n",
    "    linear_model_te = np.dot(X_test_1, weights) + bias\n",
    "    y_pred_te = sigmoid(linear_model_te)\n",
    "    te_predictions = np.round(y_pred_te)\n",
    "\n",
    "    tr_accuracy = calculate_accuracy(diabetes_y_tr_arr, tr_predictions)\n",
    "    print(f\"Train accuracy w/ learning rate {rate}:\", tr_accuracy)\n",
    "    te_accuracy = calculate_accuracy(diabetes_y_te_arr, te_predictions)\n",
    "    print(f\"Test accuracy w/ learning rate {rate}:\", te_accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44249bff-9058-409a-9b02-da3cd20fda48",
   "metadata": {},
   "source": [
    "### Decision Tree (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c67bc-7a61-4bda-a4a0-ba71160a06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 16)\n",
    "tr_scores = []\n",
    "te_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=seed)\n",
    "    clf.fit(X_tr_scaled, diabetes_y_tr_arr)\n",
    "    \n",
    "    tr_scores.append(clf.score(X_tr_scaled, diabetes_y_tr_arr))\n",
    "    te_scores.append(clf.score(X_te_scaled, diabetes_y_te_arr))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depths, tr_scores, label=\"Training Accuracy\")\n",
    "plt.plot(depths, te_scores, label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(depths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7f2f9-5529-423f-bbf4-79354fc88381",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = range(1, 16)\n",
    "tr_scores = []\n",
    "te_scores = []\n",
    "\n",
    "for leaf in leaves:\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=leaf, random_state=seed)\n",
    "    clf.fit(X_tr_scaled, diabetes_y_tr_arr)\n",
    "    \n",
    "    tr_scores.append(clf.score(X_tr_scaled, diabetes_y_tr_arr))\n",
    "    te_scores.append(clf.score(X_te_scaled, diabetes_y_te_arr))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(leaves, tr_scores, label=\"Training Accuracy\")\n",
    "plt.plot(leaves, te_scores, label=\"Testing Accuracy\")\n",
    "plt.xlabel(\"Min Leaf Samples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(leaves)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fed186-3884-4bf7-a376-d4acf2d2ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = range(9, 20)\n",
    "depths = range(2, 20)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for leaf in leaves:\n",
    "    for depth in depths:\n",
    "        clf = DecisionTreeClassifier(min_samples_leaf=leaf, max_depth=depth, random_state=seed)\n",
    "        clf.fit(X_tr_scaled, diabetes_y_tr_arr)\n",
    "\n",
    "        tr_score = clf.score(X_tr_scaled, diabetes_y_tr_arr)\n",
    "        te_score = clf.score(X_te_scaled, diabetes_y_te_arr)\n",
    "        leaf_depth = [leaf, depth]\n",
    "        scores.append([te_score, tr_score, leaf_depth])\n",
    "\n",
    "scores = sorted(scores, reverse=True)[:5]\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
